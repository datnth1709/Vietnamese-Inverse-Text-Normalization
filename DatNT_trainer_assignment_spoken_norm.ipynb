{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXUna-k4vh7Y"
   },
   "source": [
    "# Vietnamese Inverse Text Normalization - asignment description\n",
    "\n",
    "Inverse text normalization (ITN) is the task that transforms spoken to written styles. It is particularly useful in automatic speech recognition (ASR) systems where proper names are often miss-recognized by their pronunciations instead of the written forms. By applying ITN, we can improve the readability of the ASR system’s output significantly. This dataset provides data for doing ITN task in the Vietnamese language.\n",
    "\n",
    "For example:\n",
    "\n",
    "| Spoken (src)                                           | Written (tgt)      | Types                      |\n",
    "|--------------------------------------------------|--------------|----------------------------|\n",
    "| tám giờ chín phút ngày ba tháng tư năm hai nghìn | 8h9 3/4/2000 | time and date              |\n",
    "| tám mét khối năm mươi ki lô gam                  | 8m3 50 kg    | number and unit of measure |\n",
    "| không chín sáu hai bảy bảy chín chín không bốn   | 0962779904   | phone number               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LABZdO0Ty8kk"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The ITN dataset has 3 splits: _train_, _validation_, and _test_. In _train_, _validation_ splits, the input (src) and their label (tgt) are provided.\n",
    "\n",
    "| Dataset Split | Number of Instances in Split |\n",
    "| ------------- |----------------------------- |\n",
    "| Train         | 500,000                      |\n",
    "| Validation    | 2,500                       |\n",
    "| Test          | 2,500                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFJznRvvQ4jf",
    "outputId": "2edab274-9a23-497e-b70d-650e643ce443",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers==4.21.3 in /usr/local/lib/python3.7/dist-packages (4.21.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (2022.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (4.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (1.21.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (3.8.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (0.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.21.3) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.3) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.21.3) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.21.3) (3.8.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.3) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.3) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.3) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.21.3) (1.25.11)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (2.2.1)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2.5.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2022.6.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.4.5)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.10)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (4.9.1)\n",
      "Requirement already satisfied: levenshtein==0.20.2 in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.20.2)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from levenshtein==0.20.2->jiwer) (2.10.0)\n",
      "Requirement already satisfied: jarowinkler<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from rapidfuzz<3.0.0,>=2.3.0->levenshtein==0.20.2->jiwer) (1.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.21.3\n",
    "!pip install datasets sentencepiece sacrebleu jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eD3UR4a-beMF",
    "outputId": "fc703341-cafa-46e3-b41b-7f06c8e39eb3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: metrics in /usr/local/lib/python3.7/dist-packages (0.3.3)\n",
      "Requirement already satisfied: Pygments==2.2.0 in /usr/local/lib/python3.7/dist-packages (from metrics) (2.2.0)\n",
      "Requirement already satisfied: pathspec==0.5.5 in /usr/local/lib/python3.7/dist-packages (from metrics) (0.5.5)\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from metrics) (2.3.7.post1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2>=2.3.0->metrics) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install metrics\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pIXB2OeKvM98"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "referenced_widgets": [
      "6ffd01e7bc8b43a5add459eaa0fab8b7",
      "cd8db1dcd52f443f827e83fa0a599720",
      "d5c77e54e10747309e3d3eab0a7c3d4d",
      "c4980217a19a4c3fb29bfb8e3bfcb0a5",
      "8a0daa2232964836a59827468dbfe10d",
      "0118c94ef10c453f8a06fc0b9c9a61fa",
      "31ba8dd9fd7f43998080ffe718c8545c",
      "54bffcd991494955bf6110774836a00f",
      "8b2308e391e5438fa41f890036b01de1",
      "17fedf792bd54b07a422d05b12405d01",
      "4bdc4005ec4743d7a7350d96ef36d4f0"
     ]
    },
    "id": "wjOhahjUxmHU",
    "outputId": "d344ad89-f555-405f-b880-e52dd306a504"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration VietAI--spoken_norm_assignment-ada0fdcdb6b08774\n",
      "Reusing dataset parquet (/home/ailab/.cache/huggingface/datasets/VietAI___parquet/VietAI--spoken_norm_assignment-ada0fdcdb6b08774/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d07cee18c4790ae3bfd08047ca37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['src', 'tgt'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['src', 'tgt'],\n",
       "        num_rows: 500000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['src', 'tgt'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_data = load_dataset('VietAI/spoken_norm_assignment')\n",
    "norm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeH1aSBq7HYi"
   },
   "source": [
    "#### Example train/valid\n",
    "\n",
    "In the _train_, _validation_ set, the input (src) and the output (tgt) are segmented and aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Y0W27t7yABF",
    "outputId": "657d8742-6c4b-47d0-b519-24c51a7adf22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('máy', 'máy'),\n",
       " ('chỉ', 'chỉ'),\n",
       " ('được', 'được'),\n",
       " ('lưu', 'lưu'),\n",
       " ('thông', 'thông'),\n",
       " ('từ', 'từ'),\n",
       " ('sáu giờ', '6h'),\n",
       " ('đến', 'đến'),\n",
       " ('tháng chín', 'tháng 9'),\n",
       " ('các', 'các'),\n",
       " ('loại', 'loại'),\n",
       " ('ô', 'ô'),\n",
       " ('tô', 'tô'),\n",
       " ('qua', 'qua'),\n",
       " ('hầm', 'hầm'),\n",
       " ('cộng hai bẩy bốn ba bốn hai ba một sáu bẩy hai', '+27434231672'),\n",
       " ('phải', 'phải'),\n",
       " ('giữ', 'giữ'),\n",
       " ('khoảng', 'khoảng'),\n",
       " ('cách', 'cách'),\n",
       " ('ba nghìn ba trăm bẩy lăm phẩy ba trăm bốn mươi bảy oát giờ trên tấn',\n",
       "  '3375,347 wh/tấn'),\n",
       " ('chạy', 'chạy'),\n",
       " ('nhanh', 'nhanh'),\n",
       " ('nhất', 'nhất'),\n",
       " ('chín triệu ba mươi ngàn', '9.030.000'),\n",
       " ('km/giờ', 'km/giờ'),\n",
       " ('và', 'và'),\n",
       " ('chậm', 'chậm'),\n",
       " ('nhất', 'nhất'),\n",
       " ('là', 'là')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 91201\n",
    "set_name = 'train'\n",
    "list(zip(norm_data[set_name][sample_idx]['src'][90: 120], norm_data[set_name][sample_idx]['tgt'][90: 120]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QH8fBBBM7RBk"
   },
   "source": [
    "#### Example test\n",
    "\n",
    " In the _test_ splits, only the input (src) is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_eD8q1xyDUP",
    "outputId": "963d16be-4b1a-4e56-9f5b-8a4ec1fb605e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src:  ô\n",
      "tgt:  ông đỗ hữu trí chủ một ngôi nhà mới xây ở quận -69.619,290 thành phố hồ chí minh cho biết do tin tưởng chủ thầu nên ông giao toàn bộ việc đổ móng cột sàn cho họ toàn bộ các hạng mục đều có hợp đồng kể cả hợp đồng cụ thể với bên cung cấp bê tông tươi theo đó phải cung cấp bê tông mác +83412264145 để đổ sàn và cột chủ công trình/nhà có thể thuê máy trộn bê tông mini để giám sát chất lượng bê tông kết quả là mẫu bê tông chỉ có mác 81 bê tông tươi mác -3388.06939 hiện có giá khoảng 87738002236 672 ngày/ft đồng/m3 mác 1000 khoảng 458 cc đồng mác 46.056 từ -8834.746 pa/m2 đồng/m3 những nơi làm ăn gian dối thường sử dụng đá non dễ vỡ cát có nhiều tạp chất để tiết kiệm ít nhất 1000 đồng/m3 bằng cách này họ sẽ bỏ túi từ 2.067.251 -12,085 đồng/m3 bê tông tươi\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "set_name = 'valid'\n",
    "print(\"src: \", norm_data[set_name][sample_idx]['src'][0])\n",
    "print(\"tgt: \", norm_data[set_name][sample_idx]['tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['src', 'tgt'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['src', 'tgt'],\n",
       "        num_rows: 500000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['src', 'tgt'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save data to disk\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datasets import load_from_disk\n",
    "DATA_DIR = \"data/\"\n",
    "file = \"dataset.hf\"\n",
    "\n",
    "def join_words(batch):\n",
    "    source_words = batch['src']\n",
    "    target_words = batch['tgt'] \n",
    "    source = [' '.join(word) for word in source_words]\n",
    "    target = [' '.join(word) for word in target_words]\n",
    "    batch['src'] = source\n",
    "    batch['tgt'] = target\n",
    "    return batch\n",
    "\n",
    "if not Path(DATA_DIR + file).is_dir():\n",
    "    if not os.path.isdir(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "    norm_data['valid'] = norm_data['valid'].map(\n",
    "    join_words,\n",
    "    batched=True,\n",
    "    batch_size=10000\n",
    "    )\n",
    "    norm_data['train'] = norm_data['train'].map(\n",
    "        join_words,\n",
    "        batched=True,\n",
    "        batch_size=10000\n",
    "    )\n",
    "    norm_data.save_to_disk(os.path.join(DATA_DIR, file))\n",
    "\n",
    "# Load data from disk\n",
    "norm_data = load_from_disk(os.path.join(DATA_DIR, file))\n",
    "norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NFgH4TQsrvpd"
   },
   "outputs": [],
   "source": [
    "SRC_MAX_LENGTH = 100\n",
    "TGT_MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E1xvLvzAuIQr"
   },
   "outputs": [],
   "source": [
    "from transformers.file_utils import cached_path, hf_bucket_url\n",
    "from importlib.machinery import SourceFileLoader\n",
    "import os\n",
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "cache_dir = './cache'\n",
    "model_name = 'nguyenvulebinh/envibert'\n",
    "\n",
    "def download_tokenizer_files():\n",
    "    resources = ['envibert_tokenizer.py', 'dict.txt', 'sentencepiece.bpe.model']\n",
    "    for item in resources:\n",
    "        if not os.path.exists(os.path.join(cache_dir, item)):\n",
    "            tmp_file = hf_bucket_url(model_name, filename=item)\n",
    "            tmp_file = cached_path(tmp_file, cache_dir=cache_dir)\n",
    "            os.rename(tmp_file, os.path.join(cache_dir, item))\n",
    "\n",
    "def init_tokenizer():\n",
    "    download_tokenizer_files()\n",
    "    tokenizer = SourceFileLoader(\"envibert.tokenizer\",\n",
    "                                 os.path.join(cache_dir,\n",
    "                                              'envibert_tokenizer.py')).load_module().RobertaTokenizer(cache_dir)\n",
    "    return tokenizer\n",
    "\n",
    "def init_model():\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    download_tokenizer_files()\n",
    "    tokenizer = SourceFileLoader(\"envibert.tokenizer\",\n",
    "                                 os.path.join(cache_dir,\n",
    "                                              'envibert_tokenizer.py')).load_module().RobertaTokenizer(cache_dir)\n",
    "    # set encoder decoder tying to True\n",
    "    roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name,\n",
    "                                                                         model_name,\n",
    "                                                                         tie_encoder_decoder=False)\n",
    "\n",
    "    # set special tokens\n",
    "    roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "    roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n",
    "    roberta_shared.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    # sensible parameters for beam search\n",
    "    # set decoding params\n",
    "    roberta_shared.config.max_length = 100\n",
    "    roberta_shared.config.early_stopping = True\n",
    "    roberta_shared.config.no_repeat_ngram_size = 3\n",
    "    roberta_shared.config.length_penalty = 2.0\n",
    "    roberta_shared.config.num_beams = 1\n",
    "    roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size\n",
    "\n",
    "    return roberta_shared, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_hXtZx5xIHr",
    "outputId": "35bafa73-39eb-477d-c0f2-1f6d1123a6c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at nguyenvulebinh/envibert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at nguyenvulebinh/envibert and are newly initialized: ['roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oy8DSL5MYdKu"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, PreTrainedTokenizerBase\n",
    "from dataclasses import dataclass\n",
    "from transformers.utils import PaddingStrategy\n",
    "from typing import Optional, Union, Any\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# The DataCollator is used for tokenization and padding to make batch input\n",
    "@dataclass\n",
    "class DataCollatorForEnViMT:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: PreTrainedTokenizerBase,\n",
    "        model: Optional[Any] = None,\n",
    "        padding: Union[bool, str, PaddingStrategy] = True,\n",
    "        max_length: Optional[int] = None,\n",
    "        target_max_length: Optional[int] = None,\n",
    "        pad_to_multiple_of: Optional[int] = None,\n",
    "        label_pad_token_id: int = -100,\n",
    "        return_tensors: str = \"pt\"\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "        self.target_max_length = target_max_length\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "        self.label_pad_token_id = label_pad_token_id\n",
    "        self.return_tensors = return_tensors\n",
    "        \n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        features_tokenized = []\n",
    "        for feature in features:\n",
    "            src = feature['src']\n",
    "            tgt = feature['tgt']\n",
    "            if len(src) == 0 or len(tgt) == 0:\n",
    "                continue\n",
    "            temp = {}\n",
    "            # Set up the tokenizer for targets\n",
    "            temp['input_ids'] = self.tokenizer(src, max_length=self.max_length, truncation=True)[\"input_ids\"]\n",
    "            with self.tokenizer.as_target_tokenizer():\n",
    "                temp['labels'] = self.tokenizer(\n",
    "                    tgt, max_length=self.target_max_length, truncation=True\n",
    "                )[\"input_ids\"][1:]\n",
    "            features_tokenized.append(temp)                       \n",
    "        features = features_tokenized\n",
    "\n",
    "        if return_tensors is None:\n",
    "            return_tensors = self.return_tensors\n",
    "        labels = [feature[\"labels\"] for feature in features] if \"labels\" in features[0].keys() else None\n",
    "        # We have to pad the labels before calling `tokenizer.pad` as this method won't pad them and needs them of the\n",
    "        # same length to return tensors.\n",
    "        if labels is not None:\n",
    "            max_label_length = max(len(l) for l in labels)\n",
    "            if self.pad_to_multiple_of is not None:\n",
    "                max_label_length = (\n",
    "                    (max_label_length + self.pad_to_multiple_of - 1)\n",
    "                    // self.pad_to_multiple_of\n",
    "                    * self.pad_to_multiple_of\n",
    "                )\n",
    "\n",
    "            padding_side = self.tokenizer.padding_side\n",
    "            for feature in features:\n",
    "                remainder = [self.label_pad_token_id] * (max_label_length - len(feature[\"labels\"]))\n",
    "                \n",
    "                if isinstance(feature[\"labels\"], list):\n",
    "                    feature[\"labels\"] = (\n",
    "                        feature[\"labels\"] + remainder if padding_side == \"right\" else remainder + feature[\"labels\"]\n",
    "                    )\n",
    "                elif padding_side == \"right\":\n",
    "                    feature[\"labels\"] = np.concatenate([feature[\"labels\"], remainder]).astype(np.int64)\n",
    "                else:\n",
    "                    feature[\"labels\"] = np.concatenate([remainder, feature[\"labels\"]]).astype(np.int64)\n",
    "        \n",
    "        features = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=return_tensors,\n",
    "        )\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bXh6Uxa0YfLq"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForEnViMT(tokenizer, model=model, max_length=SRC_MAX_LENGTH, target_max_length=TGT_MAX_LENGTH, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jDB3VnAFcpE1"
   },
   "outputs": [],
   "source": [
    "# Define a function for evaluation\n",
    "def get_metric_compute_fn(tokenizer):\n",
    "    metric = load_metric(\"sacrebleu\")\n",
    "\n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        # In case the model returns more than the prediction logits\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "        # Replace -100s in the labels as we can't decode them\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Some simple post-processing\n",
    "        decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "        decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        return {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    return compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mponyo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ailab/DatNT/assignment1/wandb/run-20220923_040054-1w0cjzr6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ponyo/VietAI-NLP-assigment1/runs/1w0cjzr6\" target=\"_blank\">dandy-butterfly-4</a></strong> to <a href=\"https://wandb.ai/ponyo/VietAI-NLP-assigment1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ponyo/VietAI-NLP-assigment1/runs/1w0cjzr6?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbae4043580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"VietAI-NLP-assigment1\", entity=\"ponyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Yr1H2G1nYg_-"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, PreTrainedTokenizerBase\n",
    "import os\n",
    "#from metrics import get_metric_compute_fn\n",
    "\n",
    "def init_trainer(model, tokenizer, dataset, data_collator, epochs=5, batch_size=16):\n",
    "    checkpoint_path = \"./itn_checkpoints\"\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir = f\"VietAI-NLP-ITN\",\n",
    "        logging_strategy = 'steps',\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        gradient_accumulation_steps=1,\n",
    "        predict_with_generate=True,\n",
    "        save_total_limit=2,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        logging_steps=1000,\n",
    "        num_train_epochs = epochs,\n",
    "        warmup_ratio=1 / epochs,\n",
    "        logging_dir=os.path.join(checkpoint_path, 'log'),\n",
    "        overwrite_output_dir=True,\n",
    "        metric_for_best_model='bleu',\n",
    "        greater_is_better=True,\n",
    "        eval_accumulation_steps=10,\n",
    "        dataloader_num_workers=20,\n",
    "        # sharded_ddp=\"simple\",\n",
    "        #fp16=True,\n",
    "        remove_unused_columns=False,\n",
    "        report_to='wandb',\n",
    "        push_to_hub=True,\n",
    "    )\n",
    "\n",
    "    # instantiate trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=get_metric_compute_fn(tokenizer),\n",
    "        train_dataset=dataset['train'],    # Only use subset of the dataset for a quick training. Remove shard for full training,\n",
    "        eval_dataset=dataset['valid'],    # Only use subset of the dataset for a quick training. Remove shard for full training,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LeJBgMKGYij3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ailab/DatNT/assignment1/VietAI-NLP-ITN is already a clone of https://huggingface.co/datnth1709/VietAI-NLP-ITN. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = init_trainer(model, tokenizer, norm_data, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "iygvr5KDYj_v",
    "outputId": "00c1caf8-338b-47af-ae62-b9ff5fc6e186",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ailab/pytorch_env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 500000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156250\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/home/ailab/pytorch_env/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156250' max='156250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156250/156250 6:37:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.652900</td>\n",
       "      <td>0.565955</td>\n",
       "      <td>78.731511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.477003</td>\n",
       "      <td>81.397934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.479800</td>\n",
       "      <td>0.455359</td>\n",
       "      <td>81.672031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.443488</td>\n",
       "      <td>81.775255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.437754</td>\n",
       "      <td>81.857126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to VietAI-NLP-ITN/checkpoint-31250\n",
      "Configuration saved in VietAI-NLP-ITN/checkpoint-31250/config.json\n",
      "Model weights saved in VietAI-NLP-ITN/checkpoint-31250/pytorch_model.bin\n",
      "tokenizer config file saved in VietAI-NLP-ITN/checkpoint-31250/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/checkpoint-31250/special_tokens_map.json\n",
      "tokenizer config file saved in VietAI-NLP-ITN/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/special_tokens_map.json\n",
      "Deleting older checkpoint [VietAI-NLP-ITN/checkpoint-157] due to args.save_total_limit\n",
      "/home/ailab/pytorch_env/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to VietAI-NLP-ITN/checkpoint-62500\n",
      "Configuration saved in VietAI-NLP-ITN/checkpoint-62500/config.json\n",
      "Model weights saved in VietAI-NLP-ITN/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in VietAI-NLP-ITN/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/checkpoint-62500/special_tokens_map.json\n",
      "tokenizer config file saved in VietAI-NLP-ITN/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/special_tokens_map.json\n",
      "Deleting older checkpoint [VietAI-NLP-ITN/checkpoint-314] due to args.save_total_limit\n",
      "/home/ailab/pytorch_env/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to VietAI-NLP-ITN/checkpoint-93750\n",
      "Configuration saved in VietAI-NLP-ITN/checkpoint-93750/config.json\n",
      "Model weights saved in VietAI-NLP-ITN/checkpoint-93750/pytorch_model.bin\n",
      "tokenizer config file saved in VietAI-NLP-ITN/checkpoint-93750/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/checkpoint-93750/special_tokens_map.json\n",
      "tokenizer config file saved in VietAI-NLP-ITN/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/special_tokens_map.json\n",
      "Deleting older checkpoint [VietAI-NLP-ITN/checkpoint-31250] due to args.save_total_limit\n",
      "/home/ailab/pytorch_env/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to VietAI-NLP-ITN/checkpoint-125000\n",
      "Configuration saved in VietAI-NLP-ITN/checkpoint-125000/config.json\n",
      "Model weights saved in VietAI-NLP-ITN/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in VietAI-NLP-ITN/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/checkpoint-125000/special_tokens_map.json\n",
      "tokenizer config file saved in VietAI-NLP-ITN/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/special_tokens_map.json\n",
      "Deleting older checkpoint [VietAI-NLP-ITN/checkpoint-62500] due to args.save_total_limit\n",
      "/home/ailab/pytorch_env/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2500\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to VietAI-NLP-ITN/checkpoint-156250\n",
      "Configuration saved in VietAI-NLP-ITN/checkpoint-156250/config.json\n",
      "Model weights saved in VietAI-NLP-ITN/checkpoint-156250/pytorch_model.bin\n",
      "tokenizer config file saved in VietAI-NLP-ITN/checkpoint-156250/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/checkpoint-156250/special_tokens_map.json\n",
      "tokenizer config file saved in VietAI-NLP-ITN/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/special_tokens_map.json\n",
      "Deleting older checkpoint [VietAI-NLP-ITN/checkpoint-93750] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=156250, training_loss=0.8985652455078125, metrics={'train_runtime': 23847.9965, 'train_samples_per_second': 104.831, 'train_steps_per_second': 6.552, 'total_flos': 9.40655415e+16, 'train_loss': 0.8985652455078125, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to VietAI-NLP-ITN\n",
      "Configuration saved in VietAI-NLP-ITN/config.json\n",
      "Model weights saved in VietAI-NLP-ITN/pytorch_model.bin\n",
      "tokenizer config file saved in VietAI-NLP-ITN/tokenizer_config.json\n",
      "Special tokens file saved in VietAI-NLP-ITN/special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 81.8571258360715}]}\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5985e5053c3d438ab5e59c64ebe9bd1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/594M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/datnth1709/VietAI-NLP-ITN\n",
      "   f15f351..e6190ef  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4ZeEbcMC0jD"
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "The _test_ set will be normalized using the trained model. [WER](https://huggingface.co/spaces/evaluate-metric/wer) metric will be use to evaluate this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "olcfSyAB8hG5"
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77,
     "referenced_widgets": [
      "b52284feaf5d4ec9beb50c6e3dcf9b3d",
      "db30b6253ab64132acb2391994295ee3",
      "3b699cb398af4e36a27af941c53b72a6",
      "31f00d968e5246c49f3ac4d5477088e2",
      "50225edc04a148e688027cff1fb20d69",
      "e5690f29cba9451b840a772c83429a4c",
      "1c922a272e9a4d05ac43b7510b82d0c7",
      "e7fe830a14ab4e1d85334430b0600971",
      "dd3cc4d0dd9543028c7d30901b984412",
      "e137d59ac7b04a6a9b8af055ea8c448f",
      "cd12f364f10f4db1ab6862d67a10a084"
     ]
    },
    "id": "6bMWgxFeEY0w",
    "outputId": "3943f552-5d3e-429d-f6fb-04642a3b9c74"
   },
   "outputs": [],
   "source": [
    "wer = load_metric('wer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTScJJK6Grqd"
   },
   "source": [
    "### Baseline WER result on the _valid_ set (do nothing model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mb01mw9NGqK3",
    "outputId": "8678839b-7c73-4b01-ba75-2f1650241a23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31806296858909483"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [' '.join(item) for item in norm_data['valid']['src']]\n",
    "references = [' '.join(item) for item in norm_data['valid']['tgt']]\n",
    "wer.compute(predictions=predictions,\n",
    "            references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\"\n",
    "file = \"dataset.hf\"\n",
    "\n",
    "# Load data from disk\n",
    "dataset = load_from_disk(os.path.join(DATA_DIR, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/nguyenvulebinh/envibert/resolve/main/config.json from cache at /home/ailab/.cache/huggingface/transformers/13a4cc8c4ffe1ad0098bfac7e49814b38a03fd1d5559f0416552fc8b525e717a.8b442c60cec207f1183833b0ed7caf38612373e2e24c8e8c913b92c586ec7a4c\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"nguyenvulebinh/envibert\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59993\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/nguyenvulebinh/envibert/resolve/main/pytorch_model.bin from cache at /home/ailab/.cache/huggingface/transformers/9c55fc5733ce525cd30207f3ed1bf6b8c9f1b8c9eb4518ea48396c7b51187ee1.14ee70c73dc06b09e68c9f990e55001a0d90b09273d8929585ba54f38ea30d5b\n",
      "Some weights of the model checkpoint at nguyenvulebinh/envibert were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at nguyenvulebinh/envibert and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/nguyenvulebinh/envibert/resolve/main/config.json from cache at /home/ailab/.cache/huggingface/transformers/13a4cc8c4ffe1ad0098bfac7e49814b38a03fd1d5559f0416552fc8b525e717a.8b442c60cec207f1183833b0ed7caf38612373e2e24c8e8c913b92c586ec7a4c\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"nguyenvulebinh/envibert\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 59993\n",
      "}\n",
      "\n",
      "Initializing nguyenvulebinh/envibert as a decoder model. Cross attention layers are added to nguyenvulebinh/envibert and randomly initialized if nguyenvulebinh/envibert's architecture allows for cross attention layers.\n",
      "loading weights file https://huggingface.co/nguyenvulebinh/envibert/resolve/main/pytorch_model.bin from cache at /home/ailab/.cache/huggingface/transformers/9c55fc5733ce525cd30207f3ed1bf6b8c9f1b8c9eb4518ea48396c7b51187ee1.14ee70c73dc06b09e68c9f990e55001a0d90b09273d8929585ba54f38ea30d5b\n",
      "All model checkpoint weights were used when initializing RobertaForCausalLM.\n",
      "\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at nguyenvulebinh/envibert and are newly initialized: ['roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Set `config.is_decoder=True` and `config.add_cross_attention=True` for decoder_config\n",
      "loading configuration file https://huggingface.co/datnth1709/VietAI-NLP-ITN/resolve/main/config.json from cache at /home/ailab/.cache/huggingface/transformers/17a7815a2cf664f4718109f0a6c2e22777214402134ad04f41882785bb5a2656.92ce97e75ae1f266ffd2ef00546df31c7c9c925f5acc34dbf54201c12a3eb009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config EncoderDecoderConfig {\n",
      "  \"architectures\": [\n",
      "    \"EncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"nguyenvulebinh/envibert\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"architectures\": [\n",
      "      \"RobertaForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": 0,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 1024,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-05,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 514,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"roberta\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 6,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 6,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": true,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 1,\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": \"float32\",\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.20.1\",\n",
      "    \"type_vocab_size\": 1,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 59993\n",
      "  },\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder\": {\n",
      "    \"_name_or_path\": \"nguyenvulebinh/envibert\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"RobertaForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": 0,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 2,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 1024,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-05,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 514,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"roberta\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 6,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 6,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": true,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 1,\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": \"float32\",\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.20.1\",\n",
      "    \"type_vocab_size\": 1,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 59993\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 100,\n",
      "  \"model_type\": \"encoder-decoder\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": null,\n",
      "  \"vocab_size\": 59993\n",
      "}\n",
      "\n",
      "https://huggingface.co/datnth1709/VietAI-NLP-ITN/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/ailab/.cache/huggingface/transformers/tmp2aq37zo1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a554aa5477e49249f6804d543910435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/594M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/datnth1709/VietAI-NLP-ITN/resolve/main/pytorch_model.bin in cache at /home/ailab/.cache/huggingface/transformers/2ca4e11caed16518c1886982dcb1869ca84b94dcf765b9cfa7b063bcb005150f.5af94e95c93a7bc5ef2b7562af9d91de7987ffd82d14ade8222bf33a98473007\n",
      "creating metadata file for /home/ailab/.cache/huggingface/transformers/2ca4e11caed16518c1886982dcb1869ca84b94dcf765b9cfa7b063bcb005150f.5af94e95c93a7bc5ef2b7562af9d91de7987ffd82d14ade8222bf33a98473007\n",
      "loading weights file https://huggingface.co/datnth1709/VietAI-NLP-ITN/resolve/main/pytorch_model.bin from cache at /home/ailab/.cache/huggingface/transformers/2ca4e11caed16518c1886982dcb1869ca84b94dcf765b9cfa7b063bcb005150f.5af94e95c93a7bc5ef2b7562af9d91de7987ffd82d14ade8222bf33a98473007\n",
      "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
      "\n",
      "All the weights of EncoderDecoderModel were initialized from the model checkpoint at datnth1709/VietAI-NLP-ITN.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "trained_model, tokenizer = init_model()\n",
    "trained_model = trained_model.from_pretrained(\"datnth1709/VietAI-NLP-ITN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "thời báo kinh tế sài gòn online bộ trưởng âm chín chín phẩy chín tám bộ giao thông vận tải hồ nghĩa dũng đã ký quyết định phê duyệt quy hoạch sân tám trăm tám mươi chín lít bay tại tỉnh an giang giai đoạn đến mười bốn giờ năm mươi ba và định hướng đến mồng một tháng bảy có tổng nhu cầu vốn dự kiến là tám chín ba sáu tám một ba bẩy bốn năm bốn tỉ đồng bình nguyên dự án sân bay tại xã cần đăng huyện châu thành sẽ được thực hiện thành một ngàn tám trăm ba mươi bẩy giai đoạn với số vốn cần cho giai đoạn đến bốn giờ không phút là âm tám tám chấm không năm mươi tỉ đồng và giai đoạn định hướng đến một nghìn sáu trăm là âm chín ba ngàn hai trăm năm bốn phẩy bốn nghìn chín mươi bẩy tỉ đồng theo quyết định phê duyệt quy hoạch số i gi gi rờ lờ chín không không đến ngày mười hai sân bay an giang sẽ có một đường hạ cất cánh dài hai mươi ba ngàn bẩy trăm mười bốn phẩy ba nghìn tám trăm sáu mươi chín mét và rộng cộng bốn hai sáu sáu sáu không năm bốn sáu một mét đảm bảo cho các hoạt động khai thác của máy bay chín trăm một trăm hai mươi trừ rờ đờ ngang gi hoặc tương đương đường băng sẽ được nâng cấp để khả năng tiếp nhận máy bay airbus hai trăm gạch chéo tám một không xuộc đê quờ o e dét cho giai đoạn sau ngày bẩy dự kiến lượng hành khách tại sân bay này là sáu triệu một trăm bốn mươi bảy ngàn bốn trăm năm mươi hai khách/giờ cao điểm và lượng hàng hóa là hai triệu không ngàn hai trăm tấn/năm ngoài ra dự án sân bay có tổng diện tích hơn hai nhăm héc-ta này cũng sẽ bao gồm nhà dịch vụ hành khách rộng sáu trăm năm mươi chín mi li mét vuông trung tâm điều hành bay ngày hai mươi bảy và ngày hai mươi chín trạm xe dẫn đường và các công trình kỹ thuật hỗ trợ cho các hoạt động hạ cất cánh đường sân đỗ ô tô trước nhà ga sau không giờ nhà ga sẽ được nâng cấp và mở rộng đến năm mươi ba xen ti mét trên xen ti mét khối\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output:\n",
      "thời báo kinh tế sài gòn online bộ trưởng -99,98 bộ giao thông vận tải hồ nghĩa dũng đã ký quyết định phê duyệt quy hoạch sân 889 l bay tại tỉnh an giang giai đoạn đến 14h53 và định hướng đến mồng 1/7 có tổng nhu cầu vốn dự kiến là 89368137454 tỉ đồng bình nguyên dự án sân bay tại xã cần đăng huyện châu thành sẽ được thực hiện thành 1837 giai đoạn với số vốn cần cho giai đoạn đến 4h0 là -88.050 tỉ đồng và giai đoạn định hướng đến 1600 là -93.254,4097 tỉ đồng theo quyết định phê duyệt quy hoạch số ijjrl900 đến ngày 12 sân bay an giang sẽ có một đường hạ cất cánh dài 23.714,3869 mét và rộng +4266605461 mét đảm bảo cho các hoạt động khai thác của máy bay 900120-rđ-j hoặc tương đương đường băng sẽ được nâng cấp để khả năng tiếp nhận máy bay airbus 200/810/dqoez cho giai đoạn sau ngày 7 dự kiến lượng hành khách tại sân bay này là 6.147.452 khách/giờ cao điểm và lượng hàng hóa là 2.000.200 tấn/năm ngoài ra dự án sân bay có tổng diện tích hơn 25 héc-ta này cũng sẽ bao gồm nhà dịch vụ hành khách rộng 659 mm2 trung tâm điều hành bay ngày 27 và ngày 29 trạm xe dẫn đường và các công trình kỹ thuật hỗ trợ cho các hoạt động hạ cất cánh đường sân đỗ ô tô trước nhà ga sau 0h nhà ga sẽ được nâng cấp và mở rộng đến 53 cm/cc\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output without Beam-search:\n",
      "thời báo kinh tế sài gòn online bộ trưởng -99,98 bộ giao thông vận tải hồ nghĩa dũng đã ký quyết định phê duyệt quy hoạch sân 889 l bay tại tỉnh an giang giai đoạn đến 14h53 và định hướng đến mồng 1/7 có tổng nhu cầu vốn dự kiến là 89368137454 tỉ đồng bình nguyên dự án sân bay tại xã cần đăng huyện châu thành sẽ được thực hiện trong ngày 19 và ngày 22 tháng 2 theo đó quy hoạch khu vực sân\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Output with Beam-search:\n",
      "0: thời báo kinh tế sài gòn online bộ trưởng -99,98 bộ giao thông vận tải hồ nghĩa dũng đã ký quyết định phê duyệt quy hoạch sân 889 l bay tại tỉnh an giang giai đoạn đến 14h53 và định hướng đến mồng 1/7 có tổng nhu cầu vốn dự kiến là 89368137454 tỉ đồng bình nguyên dự án sân bay ở xã cần đăng huyện châu thành sẽ được thực hiện theo hình thức bê ô tê với tổng mức đầu tư lên tới hơn -\n",
      "--------------------\n",
      "1: thời báo kinh tế sài gòn online bộ trưởng -99,98 bộ giao thông vận tải hồ nghĩa dũng đã ký quyết định phê duyệt quy hoạch sân 889 l bay tại tỉnh an giang giai đoạn đến 14h53 và định hướng đến mồng 1/7 có tổng nhu cầu vốn dự kiến là 89368137454 tỉ đồng bình nguyên dự án sân bay ở xã cần đăng huyện châu thành sẽ được thực hiện theo hình thức bê ô tê với tổng mức đầu tư lên tới gần -\n",
      "--------------------\n",
      "2: thời báo kinh tế sài gòn online bộ trưởng -99,98 bộ giao thông vận tải hồ nghĩa dũng đã ký quyết định phê duyệt quy hoạch sân 889 l bay tại tỉnh an giang giai đoạn đến 14h53 và định hướng đến mồng 1/7 có tổng nhu cầu vốn dự kiến là 89368137454 tỉ đồng bình nguyên dự án sân bay ở xã cần đăng huyện châu thành sẽ được thực hiện theo hình thức bê ô tê với tổng mức đầu tư lên tới -9\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "SRC_MAX_LENGTH = 100\n",
    "TGT_MAX_LENGTH = 100\n",
    "\n",
    "idx = random.randint(0, 2500) # test set only contain 2500 sentences\n",
    "set_name = 'valid'\n",
    "sentence = dataset[set_name]['src'][idx]\n",
    "\n",
    "print(\"Input: \")\n",
    "# print(dataset['valid']['src'][idx])\n",
    "print(sentence)\n",
    "print(100 * '-')\n",
    "\n",
    "if set_name == 'valid':\n",
    "  print(\"Output groudtruth: \")\n",
    "  print(dataset['valid']['tgt'][idx])\n",
    "  print(100 * '-')\n",
    "\n",
    "print(\"Output without Beam-search: \")\n",
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer(sentence, max_length=SRC_MAX_LENGTH, truncation=True, return_tensors='pt')[\"input_ids\"]\n",
    "# generate text without beam-search\n",
    "outputs = trained_model.generate(\n",
    "    input_ids, \n",
    "    max_length=SRC_MAX_LENGTH, \n",
    "    num_return_sequences=1, \n",
    "    early_stopping=True\n",
    ")\n",
    "for i, output in enumerate(outputs):\n",
    "  output_pieces = tokenizer.convert_ids_to_tokens(output.numpy().tolist())\n",
    "  output_text = tokenizer.sp_model.decode(output_pieces)\n",
    "  print(output_text)\n",
    "print(100 * '-')\n",
    "\n",
    "\n",
    "# generate text using beam-search\n",
    "print(\"Output with Beam-search: \")\n",
    "beam_outputs = trained_model.generate(\n",
    "    input_ids, \n",
    "    max_length=SRC_MAX_LENGTH, \n",
    "    num_beams=10, \n",
    "    no_repeat_ngram_size=2, \n",
    "    num_return_sequences=3, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  output_pieces = tokenizer.convert_ids_to_tokens(beam_output.numpy().tolist())\n",
    "  output_text = tokenizer.sp_model.decode(output_pieces)\n",
    "  print(\"{}: {}\\n{}\".format(i, output_text,'-'*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SRC_MAX_LENGTH = 100\n",
    "TGT_MAX_LENGTH = 100\n",
    "\n",
    "idx = random.randint(0, 2500)\n",
    "sentence = dataset['valid']['src'][idx]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d49c3f6d6dd49f9272b571d9fad348ab55b8c6c3f691520d74ed0af1f69c3dd8"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0118c94ef10c453f8a06fc0b9c9a61fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17fedf792bd54b07a422d05b12405d01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c922a272e9a4d05ac43b7510b82d0c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31ba8dd9fd7f43998080ffe718c8545c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31f00d968e5246c49f3ac4d5477088e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e137d59ac7b04a6a9b8af055ea8c448f",
      "placeholder": "​",
      "style": "IPY_MODEL_cd12f364f10f4db1ab6862d67a10a084",
      "value": " 4.48k/? [00:00&lt;00:00, 86.3kB/s]"
     }
    },
    "3b699cb398af4e36a27af941c53b72a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7fe830a14ab4e1d85334430b0600971",
      "max": 1901,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd3cc4d0dd9543028c7d30901b984412",
      "value": 1901
     }
    },
    "4bdc4005ec4743d7a7350d96ef36d4f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50225edc04a148e688027cff1fb20d69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54bffcd991494955bf6110774836a00f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ffd01e7bc8b43a5add459eaa0fab8b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd8db1dcd52f443f827e83fa0a599720",
       "IPY_MODEL_d5c77e54e10747309e3d3eab0a7c3d4d",
       "IPY_MODEL_c4980217a19a4c3fb29bfb8e3bfcb0a5"
      ],
      "layout": "IPY_MODEL_8a0daa2232964836a59827468dbfe10d"
     }
    },
    "8a0daa2232964836a59827468dbfe10d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b2308e391e5438fa41f890036b01de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b52284feaf5d4ec9beb50c6e3dcf9b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db30b6253ab64132acb2391994295ee3",
       "IPY_MODEL_3b699cb398af4e36a27af941c53b72a6",
       "IPY_MODEL_31f00d968e5246c49f3ac4d5477088e2"
      ],
      "layout": "IPY_MODEL_50225edc04a148e688027cff1fb20d69"
     }
    },
    "c4980217a19a4c3fb29bfb8e3bfcb0a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17fedf792bd54b07a422d05b12405d01",
      "placeholder": "​",
      "style": "IPY_MODEL_4bdc4005ec4743d7a7350d96ef36d4f0",
      "value": " 3/3 [00:00&lt;00:00,  1.76it/s]"
     }
    },
    "cd12f364f10f4db1ab6862d67a10a084": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd8db1dcd52f443f827e83fa0a599720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0118c94ef10c453f8a06fc0b9c9a61fa",
      "placeholder": "​",
      "style": "IPY_MODEL_31ba8dd9fd7f43998080ffe718c8545c",
      "value": "100%"
     }
    },
    "d5c77e54e10747309e3d3eab0a7c3d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54bffcd991494955bf6110774836a00f",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b2308e391e5438fa41f890036b01de1",
      "value": 3
     }
    },
    "db30b6253ab64132acb2391994295ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5690f29cba9451b840a772c83429a4c",
      "placeholder": "​",
      "style": "IPY_MODEL_1c922a272e9a4d05ac43b7510b82d0c7",
      "value": "Downloading builder script: "
     }
    },
    "dd3cc4d0dd9543028c7d30901b984412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e137d59ac7b04a6a9b8af055ea8c448f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5690f29cba9451b840a772c83429a4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7fe830a14ab4e1d85334430b0600971": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
